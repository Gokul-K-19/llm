# -*- coding: utf-8 -*-
"""paraphrase.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P_vjCo09xHc1IuHlxS1yh3_YYUqTEVFn
"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

model_name = "ramsrigouthamg/t5_paraphraser"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

input_text = "Machine learning enables computers to learn from data."

text = "paraphrase: " + input_text + " </s>"

input_ids = tokenizer.encode(
    text,
    return_tensors="pt",
    max_length=128,
    truncation=True
).to(device)

outputs = model.generate(
    input_ids,
    max_length=128,
    num_beams=5,
    num_return_sequences=1,
    temperature=1.0,
    repetition_penalty=1.5
)

paraphrased_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

print("Original:", input_text)
print("Paraphrased:", paraphrased_text)

